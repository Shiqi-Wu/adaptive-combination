{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from toy_model import *\n",
    "import sys \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = reaction_diffusion_equation()\n",
    "dataset = data_model.genarate_training_data(500, 10, dlt_t = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ParaModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, m_dim):\n",
    "        super(CustomModel, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.relu_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], m_dim)\n",
    "        self.Q = nn.Parameter(torch.randn(m_dim, m_dim), requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = F.linear(x, self.Q)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(h_outputs, y, lace, mu, lambda1, lambda2):\n",
    "\n",
    "    g = mu * lace\n",
    "    \n",
    "    u_x = y - g\n",
    "        \n",
    "    loss1 = 0\n",
    "    loss2 = 0\n",
    "    \n",
    "    k_i_values = torch.zeros(m_dim, device=h_outputs.device)  # 确保k_i_values与h_outputs在同一设备上\n",
    "    for i in range(m_dim):\n",
    "        h_i = h_outputs[:, i]\n",
    "        \n",
    "        numerator1 = torch.sum(g * h_i) ** 2\n",
    "        denominator1 = torch.sum(g ** 2) * torch.sum(h_i ** 2)\n",
    "        \n",
    "        loss1 += numerator1 / denominator1 if denominator1 != 0 else 0\n",
    "\n",
    "        numerator2 = torch.sum((y - g) * h_i)\n",
    "        denominator2 = torch.sqrt(torch.sum(h_i ** 2))\n",
    "        k_i = numerator2 / denominator2 if denominator2 != 0 else 0\n",
    "        k_i_values[i] = k_i\n",
    "\n",
    "    predicted_u_x = torch.matmul(h_outputs, k_i_values.unsqueeze(1)).squeeze()\n",
    "    loss2 = torch.sum((predicted_u_x - u_x) ** 2)\n",
    "\n",
    "    predicted_u_x = torch.matmul(h_outputs, k_i_values.unsqueeze(1)).squeeze()\n",
    "    loss2 = torch.sum((predicted_u_x - u_x) ** 2)\n",
    "    \n",
    "    total_loss = lambda1 * loss1 + lambda2 * loss2\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "for x, y, lace in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mu: -0.2339961677789688\n"
     ]
    }
   ],
   "source": [
    "lace_mean = torch.mean(lace)\n",
    "y_mean = torch.mean(y)\n",
    "\n",
    "mu_numerator = torch.sum((lace - lace_mean) * (y - y_mean))\n",
    "mu_denominator = torch.sum((lace - lace_mean) ** 2)\n",
    "mu = mu_numerator / mu_denominator\n",
    "\n",
    "print(\"Estimated mu:\", mu.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dims = [64, 64, 64]\n",
    "m_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
